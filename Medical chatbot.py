# -*- coding: utf-8 -*-
"""Domain Adaptation .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QRJouVpzoINywi1z2RUuUQG2XlTqG45B
"""



"""# ***Libraries***"""

!pip install transformers datasets peft accelerate bitsandbytes

"""# ***Create Medical Corpus***"""

import json

# Sample medical texts (in real project, use PubMed, medical papers)
medical_corpus = [
    "Acute myocardial infarction, commonly known as a heart attack, occurs when blood flow to part of the heart muscle is blocked. Common symptoms include chest pain, shortness of breath, and nausea.",
    "Hypertension, or high blood pressure, is a chronic condition where the force of blood against artery walls is consistently too high. It can lead to serious complications including stroke and heart disease.",
    "Diabetes mellitus is a metabolic disorder characterized by elevated blood glucose levels. Type 1 diabetes results from insulin deficiency, while Type 2 involves insulin resistance.",
    "The cardiovascular system consists of the heart and blood vessels, responsible for circulating blood throughout the body to deliver oxygen and nutrients to tissues.",
    "Pneumonia is an infection that inflames air sacs in one or both lungs, which may fill with fluid. Symptoms include cough with phlegm, fever, chills, and difficulty breathing.",
    "Chronic obstructive pulmonary disease (COPD) is a progressive lung disease characterized by increasing breathlessness. It includes emphysema and chronic bronchitis.",
    "The immune system defends the body against infectious agents. White blood cells, antibodies, and other mechanisms work together to identify and eliminate pathogens.",
    "Osteoporosis is a condition where bones become weak and brittle, increasing fracture risk. It's often caused by hormonal changes, calcium deficiency, or certain medications.",
    "Alzheimer's disease is a progressive neurodegenerative disorder affecting memory, thinking, and behavior. It's the most common cause of dementia in older adults.",
    "Asthma is a chronic respiratory condition characterized by inflammation and narrowing of airways, causing wheezing, shortness of breath, and chest tightness.",
    "Rheumatoid arthritis is an autoimmune disease causing joint inflammation, pain, and eventual damage. It typically affects hands, wrists, and knees symmetrically.",
    "Hepatitis refers to liver inflammation, often caused by viral infection. Types A, B, and C are most common, each with different transmission routes and treatments.",
    "Anemia is a condition where the body lacks sufficient healthy red blood cells to carry adequate oxygen. Symptoms include fatigue, weakness, and pale skin.",
    "Gastroesophageal reflux disease (GERD) occurs when stomach acid frequently flows back into the esophagus, causing heartburn and potential tissue damage.",
    "Multiple sclerosis is an autoimmune disease affecting the central nervous system, damaging the myelin sheath that protects nerve fibers.",
    "Parkinson's disease is a progressive neurological disorder affecting movement, causing tremors, stiffness, and balance problems due to dopamine depletion.",
    "Thyroid disorders include hypothyroidism (underactive) and hyperthyroidism (overactive), affecting metabolism, energy levels, and body temperature regulation.",
    "Sepsis is a life-threatening condition arising when the body's response to infection causes tissue damage and organ failure, requiring immediate medical attention.",
    "Epilepsy is a neurological disorder characterized by recurrent seizures, caused by abnormal electrical activity in the brain.",
    "Celiac disease is an autoimmune disorder where gluten consumption damages the small intestine, preventing proper nutrient absorption.",
]

# Save as training corpus
with open('data/medical_corpus.json', 'w') as f:
    json.dump({"text": medical_corpus}, f, indent=2)

print(f"‚úÖ Created medical corpus with {len(medical_corpus)} documents")

medical_qa = [
    {
        "question": "What are the symptoms of hypertension?",
        "answer": "Hypertension often has no symptoms, which is why it's called the 'silent killer.' However, when blood pressure is extremely high, symptoms may include severe headaches, fatigue, vision problems, chest pain, difficulty breathing, and irregular heartbeat. Regular blood pressure monitoring is essential for early detection."
    },
    {
        "question": "How is diabetes diagnosed?",
        "answer": "Diabetes is diagnosed through blood tests. A fasting plasma glucose test showing levels of 126 mg/dL or higher, or an HbA1c test result of 6.5% or higher, indicates diabetes. An oral glucose tolerance test may also be used. Two separate tests showing elevated levels are typically required for diagnosis."
    },
    {
        "question": "What causes osteoporosis?",
        "answer": "Osteoporosis develops when bone resorption exceeds bone formation. Risk factors include aging, hormonal changes (especially menopause), calcium and vitamin D deficiency, sedentary lifestyle, smoking, excessive alcohol consumption, and certain medications like corticosteroids. Genetics also play a role."
    },
]

with open('data/medical_qa.json', 'w') as f:
    json.dump(medical_qa, f, indent=2)

print(f"‚úÖ Created {len(medical_qa)} medical Q&A pairs")

"""# ***Domain Adaptation Training***"""

import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from datasets import load_dataset

from datasets import load_dataset
import json

# Load YOUR raw medical text (created earlier)
dataset = load_dataset(
    "json",
    data_files="data/medical_corpus.json"
)

# Extract list of text entries
corpus = dataset["train"]["text"]

# Limit for free Colab VRAM
corpus = corpus[:200]

# Save a smaller processed version for training
with open("medical_corpus_small.json", "w") as f:
    json.dump({"text": corpus}, f, indent=2)

print(f"‚úÖ Loaded {len(corpus)} medical text samples for domain adaptation")

from datasets import load_dataset
import json

# Load your own Q&A dataset
dataset = load_dataset(
    "json",
    data_files="data/medical_qa.json"
)

# Convert to HuggingFace-friendly instruction/response format
instruction_data = []

for item in dataset["train"]:
    instruction_data.append({
        "instruction": item["question"],
        "response": item["answer"]
    })

# Save processed version
with open("medical_qa_processed.json", "w") as f:
    json.dump(instruction_data, f, indent=2)

print(f"‚úÖ Prepared {len(instruction_data)} Q&A instruction samples")

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling
from datasets import Dataset
import json

# Config
MODEL_NAME = "gpt2"  # small model for free GPU
OUTPUT_DIR = "models/medical-gpt2"

# Load tokenizer & model
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
tokenizer.pad_token = tokenizer.eos_token
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)

# Load medical corpus
with open('data/medical_corpus.json', 'r') as f:
    data = json.load(f)

dataset = Dataset.from_dict({"text": data["text"]})
dataset = dataset.train_test_split(test_size=0.2)

# Tokenization
def tokenize_fn(examples):
    return tokenizer(examples["text"], truncation=True, max_length=128, padding="max_length")

tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=["text"])

# Data collator
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# Training arguments
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=5,          # reduced for free GPU
    per_device_train_batch_size=2,
    save_steps=50,
    logging_steps=10,
    eval_steps=50,
    learning_rate=5e-5,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    data_collator=data_collator
)

# Train
trainer.train()

# Save
trainer.save_model(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)
print("‚úÖ Domain Adaptation Complete")

"""# ***Instruction Tuning on Medical Q&A using LoRA***"""

from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import Dataset
import json
from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling

# Paths
MODEL_PATH = "models/medical-gpt2"
OUTPUT_DIR = "models/medical-assistant"

# Load tokenizer & model
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, load_in_8bit=True, device_map="auto")
model = prepare_model_for_kbit_training(model)

# Add LoRA
lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["c_attn"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

# Load Q&A data
with open('data/medical_qa.json', 'r') as f:
    qa_data = json.load(f)

formatted_data = [{"text": f"### Question:\n{qa['question']}\n### Answer:\n{qa['answer']}"} for qa in qa_data]
dataset = Dataset.from_list(formatted_data).train_test_split(test_size=0.2)

# Tokenize
def tokenize_fn(examples):
    return tokenizer(examples["text"], truncation=True, max_length=128, padding="max_length")

tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=["text"])

# Data collator
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

# Training arguments
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=3,           # small for free GPU
    per_device_train_batch_size=1,
    gradient_accumulation_steps=2,
    learning_rate=2e-4,
    fp16=True,
    save_steps=20,
    logging_steps=5,
    report_to="none"
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    data_collator=data_collator
)

# Train
trainer.train()

# Save
trainer.save_model(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)
print("‚úÖ Instruction Tuning Complete")

"""# ***Test Medical Assistant***"""

from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Paths
MODEL_PATH = "models/medical-assistant"
BASE_PATH = "models/medical-gpt2"

# Load model
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
base_model = AutoModelForCausalLM.from_pretrained(BASE_PATH, load_in_8bit=True, device_map="auto")
model = PeftModel.from_pretrained(base_model, MODEL_PATH)
model.eval()

# Test questions
test_questions = [
    "What is hypertension?",
    "How can I prevent diabetes?",
    "What are the symptoms of pneumonia?",
    "Explain what asthma is."
]

for question in test_questions:
    prompt = f"### Question:\n{question}\n### Answer:\n"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=100,
            temperature=0.7,
            top_p=0.9,
            do_sample=True
        )

    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).split("### Answer:")[-1].strip()
    print(f"‚ùì Question: {question}")
    print(f"üè• Answer: {answer}\n")
    print("-"*50)

